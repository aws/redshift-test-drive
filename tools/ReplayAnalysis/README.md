# Replay Analysis README

## Introduction
The Replay analysis web app is used to analyze and compare replays. The goal of this tool is to facilitate understanding of Workload Replicator results and simplify analysis results for customers to make the right decisions for their use of Redshift.

## Preparation
### Prerequisites
* Execute replay by adding the following parameters in replay.yaml
    * analysis_iam_role
    * analysis_output
* Pre-install Node js



## Command
```
make  replay_analysis

```

## Output
* Installs all the requiremnts required to launch the web app.
* Opens Web app which helps customer to choose multiple replays for comparison.

## User Interface of the Web App <br />
The start page of the interface will prompt users to provide the bucket location(s) with replays they want to analyze. It provides users the ability to select a number of replays for analysis. 

### Steps for using Web UI

* The start page will promt user to add the following inputs:
    * Credentials Type <br />
    The credentials entered for accesing the analysis bucket can be either of the following:
        * Use a Profile 
        Enter user profile for the account where the Replay Bucket resides.
        * Use an IAM Role
        Enter IAM role for the bucket mentioned in Replay Bucket.
    * Replay Bucket <br />
    Bucket where the analysis ouput lies which was pre-generated by running replay 
    * Replays <br />
    List of replays available in the bucket for comparison
* Select the replays and click the Analysis button for generating the comparison analysis of the replay runs.

### Web UI Output
* Replay Analysis <br />
This section in the Web UI consists of following metrics:
    * Compare Throughput <br />
    It is a graph which showcases the number of queries executed per second. This data is filtered by the selected query types, users, and time range.
    * Aggregated Metrics <br />
    It is a table which displays the different percentiles of execution time, elapsed time, and queue time across selected replays. These values are representative of the selected query types, users, and time range.
    * Query Latency <br />
    It is a graph which displays the distribution of query latency.
    * Longest Running Queries<br />
    It is a table that shows the execution time metrics for each replay and also displays the top 100 running queries. 
* Replay Validation <br />
This section will give more insight into the success and validity of a given replay.Validity is defined by success and error rates, the distribution of errors, and differences in data ingested.It includes the following metrics for:
    * Query Errors <br />
    Errors encountered across selected replays.
    * Error Category Distribution <br />
    A Stacked bar chart that shows the distribution of errors that occurred across each replay and allow insight into which errors occurred most frequently.
    * COPY Ingestion Metrics <br />
    An aggregated execution metrics of COPY ingestion by replay.

